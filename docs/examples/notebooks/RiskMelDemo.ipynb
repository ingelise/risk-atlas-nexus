{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Atlas Nexus - Simple Risk Identification Demo\n",
    "\n",
    "This notebook demonstrates how to use the Risk Atlas Nexus library to identify AI risks associated with a prompt and propose a safer prompt rewrite.\n",
    "\n",
    "Based on the example from: https://github.com/IBM/risk-atlas-nexus/blob/main/docs/examples/notebooks/risk_identification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Mellea session started\n",
      "‚úì Mellea risk mitigation method defined\n"
     ]
    }
   ],
   "source": [
    "# Add Mellea integration for risk mitigation\n",
    "from mellea import generative, start_session\n",
    "\n",
    "# Initialize Mellea session\n",
    "m = start_session()\n",
    "print(\"‚úì Mellea session started\")\n",
    "\n",
    "@generative\n",
    "def rewrite_prompt_for_risk_mitigation(original_prompt: str, identified_risk: str) -> str:\n",
    "    \"\"\"Rewrite the given prompt to minimize the specified AI risk while maintaining core intent.\"\"\"\n",
    "\n",
    "print(\"‚úì Mellea risk mitigation method defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Mellea risk mitigation...\n",
      "Original prompt: Generate personalized customer service responses with recommendations.\n",
      "Risk to mitigate: Data bias in personalized recommendations\n",
      "üîß Generating safer prompt...\n",
      "‚úÖ Rewritten prompt: Craft individualized customer service replies, ensuring fairness and avoiding data bias in suggestions.\n"
     ]
    }
   ],
   "source": [
    "# Example: Test the Mellea risk mitigation function\n",
    "print(\"üß™ Testing Mellea risk mitigation...\")\n",
    "\n",
    "# Example usage\n",
    "original_prompt_text = \"Generate personalized customer service responses with recommendations.\"\n",
    "example_risk_text = \"Data bias in personalized recommendations\"\n",
    "\n",
    "try:\n",
    "    print(f\"Original prompt: {original_prompt_text}\")\n",
    "    print(f\"Risk to mitigate: {example_risk_text}\")\n",
    "    print(\"üîß Generating safer prompt...\")\n",
    "    \n",
    "    # Call the Mellea generative function with correct pattern (session first, then named params)\n",
    "    safer_prompt = rewrite_prompt_for_risk_mitigation(\n",
    "        m, \n",
    "        original_prompt=original_prompt_text, \n",
    "        identified_risk=example_risk_text\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Rewritten prompt: {safer_prompt}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error testing Mellea: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì risk-atlas-nexus already installed\n"
     ]
    }
   ],
   "source": [
    "# Install risk-atlas-nexus if not already installed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import risk_atlas_nexus\n",
    "    print(\"‚úì risk-atlas-nexus already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing risk-atlas-nexus...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"risk-atlas-nexus[ollama]\"])\n",
    "    print(\"‚úì risk-atlas-nexus installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Risk Atlas Nexus imports\n",
    "from risk_atlas_nexus.blocks.inference import (\n",
    "    OllamaInferenceEngine,\n",
    "    RITSInferenceEngine,\n",
    "    WMLInferenceEngine\n",
    ")\n",
    "from risk_atlas_nexus.blocks.inference.params import (\n",
    "    InferenceEngineCredentials,\n",
    "    OllamaInferenceEngineParams,\n",
    "    RITSInferenceEngineParams,\n",
    "    WMLInferenceEngineParams\n",
    ")\n",
    "from risk_atlas_nexus.library import RiskAtlasNexus\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úì All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup Inference Engine\n",
    "\n",
    "Choose and configure an inference engine. We'll try multiple options with fallbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-09-11 15:19:45:795] - INFO - RiskAtlasNexus - OLLAMA inference engine will execute requests on the server at http://localhost:11434.\n",
      "[2025-09-11 15:19:45:827] - INFO - RiskAtlasNexus - Created OLLAMA inference engine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Using Ollama inference engine with Granite 3.2 8B\n"
     ]
    }
   ],
   "source": [
    "def setup_inference_engine():\n",
    "    \"\"\"Try to setup an inference engine with fallbacks.\"\"\"\n",
    "    \n",
    "    # Try Ollama first (local)\n",
    "    try:\n",
    "        ollama_url = os.getenv(\"OLLAMA_API_URL\", \"http://localhost:11434\")\n",
    "        inference_engine = OllamaInferenceEngine(\n",
    "            model_name_or_path=\"granite3.2:8b\",\n",
    "            credentials=InferenceEngineCredentials(api_url=ollama_url),\n",
    "            parameters=OllamaInferenceEngineParams(\n",
    "                num_predict=1000,\n",
    "                num_ctx=8192,\n",
    "                temperature=0,\n",
    "                repeat_penalty=1\n",
    "            )\n",
    "        )\n",
    "        print(\"‚úì Using Ollama inference engine with Granite 3.2 8B\")\n",
    "        return inference_engine\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Ollama setup failed: {e}\")\n",
    "       \n",
    "    print(\"‚ùå No inference engine could be configured\")\n",
    "    print(\"Please ensure one of the following is available:\")\n",
    "    print(\"  - Ollama running locally at http://localhost:11434\")\n",
    "    return None\n",
    "\n",
    "# Setup the inference engine\n",
    "inference_engine = setup_inference_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Risk Atlas Nexus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-09-11 15:19:51:35] - INFO - RiskAtlasNexus - Created RiskAtlasNexus instance. Base_dir: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Risk Atlas Nexus library initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Risk Atlas Nexus library\n",
    "try:\n",
    "    risk_atlas_nexus = RiskAtlasNexus()\n",
    "    print(\"‚úì Risk Atlas Nexus library initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to initialize Risk Atlas Nexus: {e}\")\n",
    "    risk_atlas_nexus = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Use Case and Identify Risks\n",
    "\n",
    "We'll identify AI risks for a customer service use case involving personalized responses and recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Prompt:\n",
      "   Summarize the meeting transcript into a concise paragraph of main points.\n",
      "\n",
      "üîç Identifying AI risks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53e195b81274924b959114d0c7db95e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inferring with OLLAMA:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Risk identification completed\n",
      "üìä Found 1 potential risks\n"
     ]
    }
   ],
   "source": [
    "# Define the use case\n",
    "prompt =  \"\"\"Summarize the meeting transcript into a concise paragraph of main points.\"\"\"\n",
    "print(\"üéØ Prompt:\")\n",
    "print(f\"   {prompt}\")\n",
    "print()\n",
    "\n",
    "# Identify risks if both components are available\n",
    "if risk_atlas_nexus is not None and inference_engine is not None:\n",
    "    try:\n",
    "        print(\"üîç Identifying AI risks...\")\n",
    "        \n",
    "        risks = risk_atlas_nexus.identify_risks_from_usecases(\n",
    "            usecases=[usecase],\n",
    "            inference_engine=inference_engine,\n",
    "            taxonomy=\"ibm-risk-atlas\",\n",
    "            max_risk=5\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úì Risk identification completed\")\n",
    "        print(f\"üìä Found {len(risks)} potential risks\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Risk identification failed: {e}\")\n",
    "        risks = None\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Cannot identify risks - missing required components\")\n",
    "    if risk_atlas_nexus is None:\n",
    "        print(\"   - Risk Atlas Nexus not initialized\")\n",
    "    if inference_engine is None:\n",
    "        print(\"   - Inference engine not configured\")\n",
    "    risks = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö® Identified AI Risks:\n",
      "==================================================\n",
      "\n",
      "1. Risk: id='atlas-incorrect-risk-testing' name='Incorrect risk testing' description='A metric selected to measure or track a risk is incorrectly selected, incompletely measuring the risk, or measuring the wrong risk for the given context.' url='https://www.ibm.com/docs/en/watsonx/saas?topic=SSYOK8/wsj/ai-risk-atlas/incorrect-risk-testing.html' dateCreated=datetime.date(2024, 9, 24) dateModified=datetime.date(2025, 4, 28) isDetectedBy=None hasRelatedAction=None isDefinedByTaxonomy='ibm-risk-atlas' isPartOf='ibm-risk-atlas-governance' closeMatch=None exactMatch=None broadMatch=['nist-value-chain-and-component-integration'] narrowMatch=None relatedMatch=['credo-risk-032', 'mit-ai-causal-risk-entity-human', 'mit-ai-causal-risk-intent-unintentional', 'mit-ai-causal-risk-timing-post-deployment', 'mit-ai-risk-subdomain-6.5'] detectsRiskConcept=None tag='incorrect-risk-testing' type='non-technical' phase=None descriptor='amplified by generative AI' concern='If the metrics do not measure the risk as intended, then the understanding of that risk will be incorrect and mitigations might not be applied. If the model‚Äôs output is consequential, this might result in societal, reputational, or financial harm.'\n",
      "   Name: Incorrect risk testing\n",
      "   Description: A metric selected to measure or track a risk is incorrectly selected, incompletely measuring the risk, or measuring the wrong risk for the given context.\n",
      "\n",
      "2. Risk: id='atlas-confidential-data-in-prompt' name='Confidential data in prompt' description='Confidential information might be included as a part of the prompt that is sent to the model.' url='https://www.ibm.com/docs/en/watsonx/saas?topic=SSYOK8/wsj/ai-risk-atlas/confidential-data-in-prompt.html' dateCreated=datetime.date(2024, 3, 6) dateModified=datetime.date(2025, 5, 20) isDetectedBy=None hasRelatedAction=None isDefinedByTaxonomy='ibm-risk-atlas' isPartOf='ibm-risk-atlas-intellectual-property' closeMatch=None exactMatch=None broadMatch=['nist-intellectual-property'] narrowMatch=None relatedMatch=['ail-privacy', 'llm022025-sensitive-information-disclosure', 'mit-ai-causal-risk-entity-other', 'mit-ai-causal-risk-intent-unintentional', 'mit-ai-causal-risk-timing-post-deployment', 'mit-ai-risk-subdomain-2.1'] detectsRiskConcept=None tag='confidential-data-in-prompt' type='inference' phase=None descriptor='specific to generative AI' concern=\"If not properly developed to secure confidential data, the model might reveal confidential information or IP in the generated output. Additionally, end users' confidential information might be unintentionally collected and stored.\"\n",
      "   Name: Confidential data in prompt\n",
      "   Description: Confidential information might be included as a part of the prompt that is sent to the model.\n",
      "\n",
      "3. Risk: id='atlas-prompt-leaking' name='Prompt leaking' description='A prompt leak attack attempts to extract a model‚Äôs system prompt (also known as the system message).' url='https://www.ibm.com/docs/en/watsonx/saas?topic=SSYOK8/wsj/ai-risk-atlas/prompt-leaking.html' dateCreated=datetime.date(2024, 3, 6) dateModified=datetime.date(2025, 5, 19) isDetectedBy=None hasRelatedAction=None isDefinedByTaxonomy='ibm-risk-atlas' isPartOf='ibm-risk-atlas-robustness-prompt-attacks' closeMatch=None exactMatch=None broadMatch=['atlas-prompt-injection', 'atlas-prompt-injection', 'llm022025-sensitive-information-disclosure', 'nist-information-security'] narrowMatch=None relatedMatch=['mit-ai-causal-risk-entity-human', 'mit-ai-causal-risk-intent-intentional', 'mit-ai-causal-risk-timing-other', 'mit-ai-risk-subdomain-2.2'] detectsRiskConcept=None tag='prompt-leaking' type='inference' phase=None descriptor='specific to generative AI' concern='A successful prompt leaking attack copies the system prompt used in the model. Depending on the content of that prompt, the attacker might gain access to valuable information, such as sensitive personal information or intellectual property, and might be able to replicate some of the functionality of the model.'\n",
      "   Name: Prompt leaking\n",
      "   Description: A prompt leak attack attempts to extract a model‚Äôs system prompt (also known as the system message).\n",
      "\n",
      "4. Risk: id='atlas-hallucination' name='Hallucination' description='Hallucinations generate factually inaccurate or untruthful content with respect to the model‚Äôs training data or input. This is also sometimes referred to lack of faithfulness or lack of groundedness.' url='https://www.ibm.com/docs/en/watsonx/saas?topic=SSYOK8/wsj/ai-risk-atlas/hallucination.html' dateCreated=datetime.date(2024, 3, 6) dateModified=datetime.date(2025, 5, 20) isDetectedBy=None hasRelatedAction=None isDefinedByTaxonomy='ibm-risk-atlas' isPartOf='ibm-risk-atlas-robustness' closeMatch=None exactMatch=['nist-confabulation'] broadMatch=None narrowMatch=None relatedMatch=['granite-function-call', 'granite-answer-relevance', 'granite-relevance', 'granite-groundedness', 'llm092025-misinformation', 'mit-ai-causal-risk-entity-ai', 'mit-ai-causal-risk-intent-unintentional', 'mit-ai-causal-risk-timing-post-deployment', 'mit-ai-risk-subdomain-3.1'] detectsRiskConcept=None tag='hallucination' type='output' phase=None descriptor='specific to generative AI' concern='Hallucinations can be misleading. These false outputs can mislead users and be incorporated into downstream artifacts, further spreading misinformation. False output can harm both owners and users of the AI models. In some uses, hallucinations can be particularly consequential.'\n",
      "   Name: Hallucination\n",
      "   Description: Hallucinations generate factually inaccurate or untruthful content with respect to the model‚Äôs training data or input. This is also sometimes referred to lack of faithfulness or lack of groundedness.\n",
      "\n",
      "5. Risk: id='atlas-personal-information-in-prompt' name='Personal information in prompt' description='Personal information or sensitive personal information that is included as a part of a prompt that is sent to the model.' url='https://www.ibm.com/docs/en/watsonx/saas?topic=SSYOK8/wsj/ai-risk-atlas/personal-information-in-prompt.html' dateCreated=datetime.date(2024, 3, 6) dateModified=datetime.date(2025, 5, 20) isDetectedBy=None hasRelatedAction=None isDefinedByTaxonomy='ibm-risk-atlas' isPartOf='ibm-risk-atlas-privacy' closeMatch=None exactMatch=None broadMatch=['nist-data-privacy'] narrowMatch=None relatedMatch=['llm022025-sensitive-information-disclosure', 'mit-ai-causal-risk-entity-ai', 'mit-ai-causal-risk-intent-unintentional', 'mit-ai-causal-risk-timing-post-deployment', 'mit-ai-risk-subdomain-2.1'] detectsRiskConcept=None tag='personal-information-in-prompt' type='inference' phase=None descriptor='specific to generative AI' concern='If personal information or sensitive personal information is included in the prompt, it might be unintentionally disclosed in the models‚Äô output. In addition to accidental disclosure, prompt data might be stored or later used for other purposes like model evaluation and retraining, and might appear in their output if not properly removed.\\xa0'\n",
      "   Name: Personal information in prompt\n",
      "   Description: Personal information or sensitive personal information that is included as a part of a prompt that is sent to the model.\n"
     ]
    }
   ],
   "source": [
    "# Display the identified risks\n",
    "if risks is not None and len(risks) > 0:\n",
    "    # risks is List[List[Risk]] - get the first (and only) list of risks for our single use case\n",
    "    use_case_risks = risks[0] if risks else []\n",
    "    \n",
    "    if len(use_case_risks) > 0:\n",
    "        print(\"üö® Identified AI Risks:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        for i, risk in enumerate(use_case_risks, 1):\n",
    "            # risk is a Risk object, not a dictionary\n",
    "            print(f\"\\n{i}. Risk: {str(risk)}\")\n",
    "            \n",
    "            # Try to access risk attributes if available\n",
    "            try:\n",
    "                if hasattr(risk, 'name'):\n",
    "                    print(f\"   Name: {risk.name}\")\n",
    "                if hasattr(risk, 'description'):\n",
    "                    print(f\"   Description: {risk.description}\")\n",
    "                if hasattr(risk, 'category'):\n",
    "                    print(f\"   Category: {risk.category}\")\n",
    "                if hasattr(risk, 'severity'):\n",
    "                    print(f\"   Severity: {risk.severity}\")\n",
    "                if hasattr(risk, 'mitigation'):\n",
    "                    print(f\"   Mitigation: {risk.mitigation}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   (Risk details not accessible: {e})\")\n",
    "    else:\n",
    "        print(\"‚úì No specific risks identified for this use case\")\n",
    "        \n",
    "elif risks is not None and len(risks) == 0:\n",
    "    print(\"‚úì No specific risks identified for this use case\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Risk analysis was not performed\")\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö® Identified AI Risks:\n",
      "==================================================\n",
      "Original prompt: Summarize the meeting transcript into a concise paragraph of main points.\n",
      "Risk to mitigate: Incorrect risk testing\n",
      "‚úÖ Rewritten prompt: Summarize the meeting transcript focusing on main points, ensuring the chosen metric accurately reflects and measures the relevant risk in this context.\n",
      "Original prompt: Summarize the meeting transcript into a concise paragraph of main points.\n",
      "Risk to mitigate: Confidential data in prompt\n",
      "‚úÖ Rewritten prompt: Summarize the meeting transcript, excluding any confidential information, into a concise paragraph of main points.\n",
      "Original prompt: Summarize the meeting transcript into a concise paragraph of main points.\n",
      "Risk to mitigate: Prompt leaking\n",
      "‚úÖ Rewritten prompt: Summarize the meeting transcript, focusing on key topics and actions, without revealing internal AI communication guidelines.\n",
      "Original prompt: Summarize the meeting transcript into a concise paragraph of main points.\n",
      "Risk to mitigate: Hallucination\n",
      "‚úÖ Rewritten prompt: Summarize the meeting transcript, ensuring all information is grounded in factual accuracy and reflects the actual discussion.\n",
      "Original prompt: Summarize the meeting transcript into a concise paragraph of main points.\n",
      "Risk to mitigate: Personal information in prompt\n",
      "‚úÖ Rewritten prompt: Summarize the meeting transcript, excluding any personal or sensitive personal information, into a concise paragraph of main points.\n"
     ]
    }
   ],
   "source": [
    "original_prompt_text = prompt\n",
    "\n",
    "# Display the identified risks\n",
    "if risks is not None and len(risks) > 0:\n",
    "    # risks is List[List[Risk]] - get the first (and only) list of risks for our single use case\n",
    "    use_case_risks = risks[0] if risks else []\n",
    "    original_prompt = usecase\n",
    "    if len(use_case_risks) > 0:\n",
    "        print(\"üö® Identified AI Risks:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        for i, risk in enumerate(use_case_risks, 1):\n",
    "\n",
    "            try:\n",
    "                # risk is a Risk object, not a dictionary\n",
    "                print(f\"Original prompt: {original_prompt_text}\")\n",
    "                print(f\"Risk to mitigate: {str(risk.name)}\")\n",
    "                \n",
    "                # Call the Mellea generative function with correct pattern (session first, then named params)\n",
    "                safer_prompt = rewrite_prompt_for_risk_mitigation(\n",
    "                    m, \n",
    "                    original_prompt=original_prompt_text, \n",
    "                    identified_risk=risk.description\n",
    "                )\n",
    "                \n",
    "                print(f\"‚úÖ Rewritten prompt: {safer_prompt}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error testing Mellea: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "            \n",
    "    else:\n",
    "        print(\"‚úì No specific risks identified for this use case\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
