{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Atlas Nexus: Quick Start Guide\n",
    "\n",
    "\n",
    "## Dependencies\n",
    "Tip: Ensure you have followed installation instructions for the risk_atlas_nexus library\n",
    "\n",
    "```\n",
    "git clone git@github.com:IBM/risk-atlas-nexus.git\n",
    "cd risk-atlas-nexus\n",
    "python -m venv vrisk-atlas-nexus\n",
    "source vrisk-atlas-nexus/bin/activate\n",
    "pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from rich import print\n",
    "from risk_atlas_nexus.ai_risk_ontology.datamodel.ai_risk_ontology import Risk, LLMIntrinsic\n",
    "from risk_atlas_nexus import RiskAtlasNexus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Risk Atlas Nexus project provides an ontology combining an AI risk view (taxonomies, risks, actions) with an AI model view (AI systems, AI models, model evaluations) into one coherent schema.\n",
    "\n",
    "AI Risks were collected from IBM Risk Atlas, IBM Granite Guardian, MIT AI Risk Repository, NIST Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile, the AILuminate Benchmark, Credo's Unified Control Framework, and OWASP Top 10 for Large Language Model Applications. \n",
    "\n",
    "You can use the python library methods to quickly explore available risks, relations and actions, as well as to detect potential risks in your usecase.\n",
    "\n",
    "Important references:\n",
    "- [LinkML schema documentation](https://ibm.github.io/risk-atlas-nexus/ontology/)\n",
    "- [LinkML instance data for an example knowledge graph](https://github.com/IBM/risk-atlas-nexus/blob/main/src/risk_atlas_nexus/data/knowledge_graph/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this notebook\n",
    "\n",
    "This notebook contains three sections. Section 1 showcases the default functionality, while Sections 2-3 exhibit useful configurations. \n",
    "\n",
    "1. How to use Risk Atlas Nexus with default configuration?\n",
    "> In this section, we demonstrate a default method to use Risk Alas Nexus to explore risks and related risks\n",
    "\n",
    "2. How to use Risk Atlas Nexus to filter results for specific taxonomy?\n",
    "> We provide guidance on filtering the results for a specific taxonomies. This section highlights the ability to filter the taxonomy content.\n",
    "\n",
    "3. Bring Your Own Taxonomies/Risks/Actions\n",
    "> Risk Atlas Nexus allows users to define custom Taxonomies/Risks/Actions. In this section, we will show you how to load and configure your own data instances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use case: Risk Atlas Nexus with default configuration\n",
    "Create a new instance of Risk Atlas Nexus and use it to explore the risks.  By default, it loads in all data from [data folder](../../src/risk_atlas_nexus/data/knowledge_graph/README.md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran = RiskAtlasNexus() # no args, so default configuration \n",
    "\n",
    "all_risks = ran.get_all_risks()\n",
    "print(f\"\\n# Total risks available : {len(all_risks)}\") # 518\n",
    "\n",
    "# Let's just print out a few for now\n",
    "print(f\"\\n# First 2 risks in list \") \n",
    "print(all_risks[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Explore risk object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Each risk is returned as a pydantic \"Risk\" object as defined in risk_atlas_nexus.ai_risk_ontology.datamodel.ai_risk_ontology\n",
    "toxic_risk = ran.get_risk(id='atlas-toxic-output')\n",
    "print(f\"\\n# Get a risk by ID, 'atlas-toxic-output'  \") \n",
    "print(dict(toxic_risk))\n",
    "\n",
    "# Explore related risks\n",
    "print(f\"\\n# Get full entry for each related risks by ID for 'atlas-toxic-output' \") \n",
    "related_risks = ran.get_related_risks(id='atlas-toxic-output')\n",
    "print(related_risks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Related risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore related risks\n",
    "print(f\"\\n# Get the related risk ids by ID for 'atlas-toxic-output'\") \n",
    "related_risk_ids = ran.get_related_risks(id='atlas-toxic-output')\n",
    "print(related_risk_ids)\n",
    "\n",
    "# For related risks, maybe you might want the full risk to be returned, instead of just the ID\n",
    "print(f\"\\n# Get full entry for each related risks by ID for 'atlas-toxic-output' \") \n",
    "related_risks = ran.get_related_risks(id='atlas-toxic-output')\n",
    "print(related_risks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Risk Actions\n",
    "\n",
    "Each risk may have the relationship 'hasRelatedAction', a relationship where an entity relates to an action.  We can view all actions available, or drill down into how specific actions are related to a risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_actions = ran.get_all_actions()\n",
    "print(f\"\\n# Total actions available : {len(all_actions)}\") # 237\n",
    "\n",
    "# Let's just print out a few for now\n",
    "print(f\"\\n# First 2 actions in list \") \n",
    "print(all_actions[:2])\n",
    "\n",
    "# View an individual action by ID. Each action is returned as a pydantic \"Action\" object as defined in risk_atlas_nexus.ai_risk_ontology.datamodel.ai_risk_ontology\n",
    "an_action = ran.get_action_by_id('GV-1.3-001')\n",
    "print(f\"\\n# Get an action by ID, 'GV-1.3-001' \") \n",
    "print(dict(an_action))\n",
    "\n",
    "# Get any actions for the IBM risk atlas risk toxic output\n",
    "print(f\"\\n# Get the linked actions by ID for 'atlas-toxic-output'\") \n",
    "actions_for_toxic_output = ran.get_related_actions(id='atlas-toxic-output')\n",
    "print(actions_for_toxic_output) # 0 expected\n",
    "\n",
    "# Hmm, no linked actions recorded.  Let's try the related risks?\n",
    "related_actions = []\n",
    "related_risks = ran.get_related_risks(id='atlas-toxic-output')\n",
    "for a_risk in related_risks:\n",
    "    related_actions.extend(ran.get_related_actions(id=a_risk.id))\n",
    "\n",
    "print(f\"\\n# Get the actions for the risks which are marked as related to'atlas-toxic-output'\") \n",
    "print(related_actions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Risk Controls\n",
    "\n",
    "Each risk may have the relationship 'isDetectedBy', a relationship where a risk, risk source, consequence, or impact is detected by a risk control.  We can view all risk controls available, or drill down into how specific controls are related to a risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_risk_controls = ran.get_all_risk_controls()\n",
    "print(f\"\\n# Total risk controls available : {len(all_risk_controls)}\") # 13\n",
    "\n",
    "# Let's just print out a few for now\n",
    "print(f\"\\n# First 2 risk controls in list \") \n",
    "print(all_risk_controls[:2])\n",
    "\n",
    "# View an individual risk control by ID. Each risk control is returned as a pydantic \"RiskControl\" object as defined in risk_atlas_nexus.ai_risk_ontology.datamodel.ai_risk_ontology\n",
    "a_risk_control = ran.get_risk_control('gg-function-call-detection')\n",
    "print(f\"\\n# Get a risk control by ID, 'gg-function-call-detection' \") \n",
    "print(dict(a_risk_control))\n",
    "\n",
    "# Get any risk controls for the risk granite-function-call\n",
    "print(f\"\\n# Get the linked risk controls by ID for 'granite-function-call\") \n",
    "controls_for_granite_function_call = ran.get_related_risk_controls(id='granite-function-call')\n",
    "print(controls_for_granite_function_call) # 1 expected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Risk Incidents\n",
    "\n",
    "Risk incidents can also be modelled using the Risk Atlas Nexus.  We can view all risk incidents available, or drill down into a specific incident.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_risk_incidents = ran.get_risk_incidents()\n",
    "print(f\"\\n# Total risk incidents available : {len(all_risk_incidents)}\") # 0\n",
    "\n",
    "# Let's just print out a few for now\n",
    "print(f\"\\n# First 2 risk incidents in list \") \n",
    "print(all_risk_incidents[:2])\n",
    "\n",
    "# View an individual risk incident by ID. Each risk incident is returned as a pydantic \"RiskIncident\" object as defined in risk_atlas_nexus.ai_risk_ontology.datamodel.ai_risk_ontology\n",
    "a_risk_incident = ran.get_risk_incident(id='ibm-ai-risk-atlas-ri-toxic-and-aggressive-chatbot-responses')\n",
    "print(f\"\\n# Get a risk incident by ID, 'ibm-ai-risk-atlas-ri-toxic-and-aggressive-chatbot-responses'\") \n",
    "if a_risk_incident:\n",
    "    print(dict(a_risk_incident))\n",
    "else:\n",
    "    print(f\"\\n# Risk incident 'ibm-ai-risk-atlas-ri-toxic-and-aggressive-chatbot-responses' not found\") \n",
    "\n",
    "# Get any risk incidents which are linked to the IBM risk atlas risk harmful output\n",
    "print(f\"\\n# Get the linked risk incidents by ID for 'atlas-toxic-output'\") \n",
    "linked_incidents = ran.get_related_risk_incidents(risk_id='atlas-toxic-output')\n",
    "print(linked_incidents) # 0 expected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Evaluations\n",
    "\n",
    "AI Evaluations (LLMBenchmarks) can also be modelled using the Risk Atlas Nexus.  We can view all evaluations available, or drill down into a specific evaluation.\n",
    "Ai Evaluations may have additional metadata associated with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_evaluations = ran.get_all_evaluations()\n",
    "print(f\"\\n# Total evaluations available : {len(all_evaluations)}\") # 02\n",
    "\n",
    "# Let's just print out a few for now\n",
    "print(f\"\\n# First 2 evaluations in list \") \n",
    "print(all_evaluations[:2])\n",
    "\n",
    "# View an individual evaluation by ID. Each evaluation is returned as a pydantic \"AiEval\" object as defined in risk_atlas_nexus.ai_risk_ontology.datamodel.ai_risk_ontology\n",
    "an_evaluation = ran.get_evaluation(id='stanford-fmti')\n",
    "print(f\"\\n# Get an evaluation by ID, 'stanford-fmti'\") \n",
    "if an_evaluation:\n",
    "    print(dict(an_evaluation))\n",
    "else:\n",
    "    print(f\"\\n# Evaluation 'stanford-fmti' not found\") \n",
    "\n",
    "# Get any evaluations which are linked to the IBM risk atlas risk 'lack of model transparency'\n",
    "print(f\"\\n# Get the linked evaluations by ID for 'atlas-lack-of-model-transparency'\") \n",
    "linked_evaluations = ran.get_related_evaluations(risk_id='atlas-lack-of-model-transparency')\n",
    "print(linked_evaluations) # 1 expected\n",
    "\n",
    "# Benchmark metadata card if available\n",
    "benchmark_metadata_cards = ran.get_benchmark_metadata_cards()\n",
    "# Let's just print out a few for now\n",
    "print(f\"\\n# First 2 benchmark_metadata_cards in list \") \n",
    "print(benchmark_metadata_cards[:2])\n",
    "\n",
    "# View an individual benchark metadata card by ID. Each benchark metadata card is returned as a pydantic \"BenchmarkMetadata\" object as defined in risk_atlas_nexus.ai_risk_ontology.datamodel.ai_risk_ontology\n",
    "a_benchmark_metadata_card = ran.get_benchmark_metadata_card(id='stanford-fmti')\n",
    "print(f\"\\n# Get an benchmark_metadata_card by ID, 'stanford-fmti'\") \n",
    "if a_benchmark_metadata_card:\n",
    "    print(dict(a_benchmark_metadata_card))\n",
    "else:\n",
    "    print(f\"\\n# Benchark metadata card  'stanford-fmti' not found\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7 Documentation and Datasets\n",
    "You might also be interested in inspecting the documentation and datsets within the library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents = ran.get_documents()\n",
    "print(f\"\\n# Total documents available : {len(all_documents)}\") # 02\n",
    "\n",
    "# Let's just print out a few for now\n",
    "print(f\"\\n# First 2 documents in list \") \n",
    "print(all_documents[:2])\n",
    "\n",
    "# View an individual document by ID. Each evaluation is returned as a pydantic \"Documentation\" object as defined in risk_atlas_nexus.ai_risk_ontology.datamodel.ai_risk_ontology\n",
    "a_document = ran.get_document(id='10a99803d8afd656')\n",
    "print(f\"\\n# Get a document by ID, '10a99803d8afd656'\") \n",
    "if a_document:\n",
    "    print(dict(a_document))\n",
    "else:\n",
    "    print(f\"\\n# Document '10a99803d8afd656' not found\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = ran.get_datasets()\n",
    "print(f\"\\n# Total datasets available : {len(all_datasets)}\") # 02\n",
    "\n",
    "# Let's just print out a few for now\n",
    "print(f\"\\n# First 2 datasets in list \") \n",
    "print(all_datasets[:2])\n",
    "\n",
    "# View an individual dataset by ID. Each dataset is returned as a pydantic \"Dataset\" object as defined in risk_atlas_nexus.ai_risk_ontology.datamodel.ai_risk_ontology\n",
    "a_dataset= ran.get_dataset(id='truthfulqa/truthful_qa')\n",
    "print(f\"\\n# Get a dataset by ID, 'truthfulqa/truthful_qa'\") \n",
    "if a_dataset:\n",
    "    print(dict(a_dataset))\n",
    "else:\n",
    "    print(f\"\\n# Dataset 'truthfulqa/truthful_qa' not found\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7 Stakeholders\n",
    "You can inspect the stakeholders in the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stakeholders = ran.get_stakeholders()\n",
    "print(f\"\\n# Total stakeholders available : {len(all_stakeholders)}\") # 02\n",
    "\n",
    "# Let's just print out a few for now\n",
    "print(f\"\\n# First 2 stakeholders in list \") \n",
    "print(all_stakeholders[:2])\n",
    "\n",
    "# View an individual stakeholder by ID. Each stakeholder is returned as a pydantic \"Stakeholder\" object as defined in risk_atlas_nexus.ai_risk_ontology.datamodel.ai_risk_ontology\n",
    "a_stakeholder = ran.get_stakeholder(id='csiro-stakeholder-ai-technology-producers')\n",
    "print(f\"\\n# Get a stakeholder by ID, 'csiro-stakeholder-ai-technology-producers'\") \n",
    "if a_stakeholder:\n",
    "    print(dict(a_stakeholder))\n",
    "else:\n",
    "    print(f\"\\n# Stakeholder 'csiro-stakeholder-ai-technology-producers' not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.8 Intrinsics and Adapters\n",
    "\n",
    "The LLM intrinsics are available for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_intrinsics = ran.get_intrinsics()\n",
    "print(f\"\\n# Total intrinsics available : {len(all_intrinsics)}\") \n",
    "# Let's just print out a few for now\n",
    "print(f\"\\n# First 2 intrinsics in list \") \n",
    "print(all_intrinsics[:2])\n",
    "\n",
    "# View an individual intrinsic by ID. Each intrinsic is returned as a pydantic \"LLMIntrinsic\" object as defined in risk_atlas_nexus.ai_risk_ontology.datamodel.ai_risk_ontology\n",
    "an_intrinsic = ran.get_intrinsic(id='ibm-factuality-intrinsic-ad')\n",
    "print(f\"\\n# Get an intrinsic by ID, 'ibm-factuality-intrinsic-ad'\") \n",
    "if an_intrinsic:\n",
    "    print(dict(an_intrinsic))\n",
    "else:\n",
    "    print(f\"\\n# LLM intrinsic 'ibm-factuality-intrinsic-ad' not found\") \n",
    "\n",
    "# Get any intrinsics which are linked to the IBM risk atlas risk 'atlas-hallucination'\n",
    "print(f\"\\n# Get the linked intrinsics by ID for 'atlas-hallucination'\") \n",
    "linked_intrinsics = ran.get_related_intrinsics(risk_id='atlas-hallucination')\n",
    "print(linked_intrinsics) # 1 expected\n",
    "\n",
    "# We can do the same with adapters\n",
    "adapters = ran.get_adapters()\n",
    "# Let's just print out a few for now\n",
    "print(f\"\\n# First 2 adapters in list \") \n",
    "print(adapters[:2])\n",
    "\n",
    "# View an individual adapter by ID. Each adapter is returned as a pydantic \"Adapter\" object as defined in risk_atlas_nexus.ai_risk_ontology.datamodel.ai_risk_ontology\n",
    "an_adapter = ran.get_adapter(id='ibm-factuality-adapter-granite-3.3-8b-instruct-lora-query-rewrite')\n",
    "print(f\"\\n# Get an adapter by ID, 'ibm-factuality-adapter-granite-3.3-8b-instruct-lora-query-rewrite\") \n",
    "if an_adapter:\n",
    "    print(dict(an_adapter))\n",
    "else:\n",
    "    print(f\"\\n# Adapter 'ibm-factuality-adapter-granite-3.3-8b-instruct-lora-query-rewrite' not found\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use case: Risk Atlas Nexus results filtered by taxonomies\n",
    "\n",
    "First, we will examine which taxonomies are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_taxonomies = ran.get_all_taxonomies()\n",
    "print(f\"\\n# Total taxonomies available : {len(all_taxonomies)}\") # 9\n",
    "print(f\"\\n# Taxonomy IDs available : {[taxonomy.id for taxonomy in all_taxonomies]}\") # 9\n",
    "\n",
    "# Let's just print out a few for now\n",
    "print(f\"\\n# First 2 taxonomies in list \") \n",
    "print(all_taxonomies[:2])\n",
    "\n",
    "# View an individual taxonomy by ID. Each taxonomy is returned as a pydantic \"RiskTaxonomy\" object as defined in risk_atlas_nexus.ai_risk_ontology.datamodel.ai_risk_ontology\n",
    "a_taxonomy = ran.get_taxonomy_by_id('nist-ai-rmf')\n",
    "print(f\"\\n# Get a taxonomy by ID, 'nist-ai-rmf' \") \n",
    "print(dict(a_taxonomy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at the risks which are coming from NIST AI Risk Management Framework (AI RMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nist_risks = ran.get_all_risks(taxonomy='nist-ai-rmf')\n",
    "print(f\"\\n# Total risks available : {len(all_risks)}\") # 518\n",
    "print(f\"\\n# Total NIST risks available : {len(all_nist_risks)}\") # 12\n",
    "\n",
    "# Let's just print out a few for now\n",
    "print(f\"\\n# First 2 risks in NIST risk list \") \n",
    "print(all_nist_risks[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran.get_all_risks(taxonomy='ai-risk-taxonomy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Usecase: Bring Your Own Taxonomies/Risks/Actions\n",
    "\n",
    "You can add your own risk definitions by adding yaml to your own directory and providing the path as an argument to the RAN when creating it.  \n",
    "Ensure the risks comply with [the schema](../../../docs/ontology/index.md)\n",
    "\n",
    "#### 3.1 Add your YAML definitions\n",
    "Add one or more yaml files to your chosen directory.  For example, to add a new risk, create a file with the following content .\n",
    "\n",
    "```\n",
    "- id: my-own-risk\n",
    "  name: A very risky AI behaviour\n",
    "  description: An LLM-based system is often very risky\n",
    "  isDefinedByTaxonomy: my-taxonomy\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance which extends the graph with your custom definitions\n",
    "my_base_dir='<my_user_input_dir_path>'\n",
    "my_extended_ran = RiskAtlasNexus(base_dir=my_base_dir)\n",
    "my_extended_risks = my_extended_ran.get_all_risks()\n",
    "print(f\"\\n# Total risks available : {len(my_extended_risks)}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Exporting your graph\n",
    "You may wish to export your extended graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the total graph\n",
    "my_output_dir='<my_output_dir_path>'\n",
    "my_extended_ran.export(my_output_dir)\n",
    "print(f\"\\n# Graph exported to: {my_output_dir}\") \n",
    "\n",
    "# Check your risk is in the graph\n",
    "my_risk = my_extended_ran.get_risk(id='my-own-risk')\n",
    "print(f\"\\n# Get my own risk by ID, 'my-own-risk'  \") \n",
    "print(dict(my_risk))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vrisk-atlas-nexus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
